# Agent Guide — Financial Data Analysis (board-pack pipeline)

This repo ingests messy board-pack financials (PDF/XLSX/CSV), normalises them into a consistent database schema, prioritises what matters (board-relevant “findings”), and generates a board-style PDF report.

This document captures the current architecture + rules, and the specific improvements we’ve started implementing (from the recent thread).

## Project objective

Help a board member go from “huge pack, too much noise” to **the 2–3 most important issues**:

- Detect what changed (MoM / YoY / vs Budget / YTD)
- Calibrate whether it matters (vs “typical range” / materiality)
- Challenge management with evidence-backed questions
- Surface **restatements / goalpost moves** (e.g., budget changed after the quarter)

Key principle: **workflow stays simple**, but the data model stays **auditable**.

## High-level pipeline (Inputs → Middle → Outputs)

### Inputs

- **Board packs**: usually PDF (multi-page, layout-heavy), sometimes scanned.
- **Structured files**: XLSX/CSV exports.
- **Uploads**: via the web client.

Constraints and real-world issues:

- Packs arrive at different times.
- Formats differ month-to-month.
- Content can be revised / restated.
- PDF extraction is error-prone (layout, OCR, footnotes, page numbers).

### Middle (Core data layers)

There are three key layers; keep them conceptually separate:

1) **Raw extracted facts** (messy but complete)
- Table: `extracted_facts_raw` (added in migration `database/migrations/006_add_documents_raw_facts_and_findings.sql`).
- Stores: raw line item text, period labels, values, provenance (document/page/table/col), extraction method, confidence.

2) **Canonical facts** (stable schema)
- Table: `financial_metrics`.
- Contains mapped `line_item_id`, `period_id`, `value_type` (Actual/Budget/Prior Year), value, currency.
- Also contains provenance hooks: `document_id`, `source_page`, `source_table`, `source_col`, `extraction_method`, `confidence`.

3) **Findings** (prioritised board issues)
- Table: `reconciliation_findings`.
- Deterministic checks + prioritisation output.
- Contains structured `evidence` JSON to link back to exact sources.

### Outputs

- **Board-style PDF report**: `server/app/services/report_generator.py`
  - KPI summary/trend
  - Top findings
  - Questions
  - Appendix tables

- **Findings** used for prioritisation:
  - Generated by `server/app/services/findings_engine.py`
  - Surfaced by the report generator in “Top Findings” and “Questions (From Findings)”.

## Current implemented design rules (from the thread)

### A) “Split-brain” risk (client vs server limits)
File size limits can exist in multiple places (client validation, API server, proxy). We raised the repo’s upload limit to **12MB**.

- Client: `client/src/components/FileUpload.tsx`
- Server: `server/app/api/v1/endpoints/upload.py`

### B) Report must consume only “highest quality” metrics
Observed failure mode: report shows nonsense like `Revenue = 2` (PDF footnote/page-number extraction leakage).

Rule:
- For each `(line_item, period_label, value_type)`, the report should use **one best candidate**.
- Obvious garbage is filtered out (e.g., tiny values for headline KPIs).

Implementation:
- Central selector module: `server/app/services/fact_selector.py`
  - `best_metric_candidate(...)` returns value + provenance (doc/page/confidence/method)
  - `find_latest_usable_month(...)` picks the latest month with usable Actual

The report narrative now includes evidence like:
- `Evidence: Actual source: doc X pY (conf 0.70)`

### C) Findings are the prioritisation engine
Board members scan for:
- deltas vs prior month
- deltas vs budget
- YoY deltas
- “is this within normal volatility?” (LTM min/max range)
- “does this need a board question?”

Implementation:
- `server/app/services/findings_engine.py` generates deterministic findings.
- Config: `config/board_pack.yaml`

Current finding types:
- `boardpack_revenue_summary` (v0.4 narrative-style revenue finding)
- `cross_document_restatement` (detects differences across packs for same metric/period)

### D) Restatements / “goalpost move” detection
We explicitly want to catch management changing budget targets after the fact.

Rule:
- If the same metric/period/value_type differs across different `document_id`s beyond thresholds,
  create a `reconciliation_findings` record.

Config:
- `config/board_pack.yaml`
  - `reconciliation.restatement.pct_threshold`
  - `reconciliation.restatement.abs_threshold_gbp`

Implementation:
- `server/app/services/findings_engine.py` (_find_cross_document_restatements)

## Canonical vs legacy (avoid duplicate pipelines)

Agents should extend the **canonical** path only. If you add new logic, wire it into the canonical path rather than creating new “v2” scripts.

### Canonical entrypoints (used)

- Server entrypoint: `server/main.py`
  - Started in production by `scripts/deploy-start.sh`.
  - Exposes API routes via `server/app/api/v1/router.py`.

- Upload endpoint: `server/app/api/v1/endpoints/upload.py`
  - Validates extension/size.
  - Writes file to `data/`.
  - Calls pipeline processor.

- Pipeline orchestrator: `server/app/services/pipeline_processor.py`
  - Canonical ingestion:
    - PDFs route to `server/app/services/ingest_pdf.py`
    - XLSX/CSV route to `server/app/services/extraction.py` → `field_mapper.py` → `normalization.py` → `persistence.py`
  - Derived metrics: `server/app/services/calc_metrics.py`
  - Prioritisation: `server/app/services/findings_engine.py`
  - Report: `server/app/services/report_generator.py`

- Background worker: `server/app/core/background_tasks.py`
  - Runs ingest → metrics → findings.

### Legacy / do-not-extend

- `server/main_old.py`
  - Older FastAPI app with overlapping routes and embedded pipeline calls.
  - Not referenced by the current deploy script/docs (canonical is `server/main.py`).
  - Keep only for archaeology; do not add features here.

- Documentation drift:
  - Prior docs referenced a `server/scripts/` tree, but the code lives in `server/app/services/`.
  - Treat `server/app/services/` as canonical.

## Repo schematic (what calls what)

### Upload path
- Client UI uploads file.
- API: `server/app/api/v1/endpoints/upload.py` → writes to `data/` → triggers pipeline.

### Pipeline
- `server/app/services/pipeline_processor.py`
  - `ingest_file(...)`
    - PDF: `ingest_pdf.py`
    - XLSX/CSV: `extraction.py` → `field_mapper.py` → `normalization.py` → `persistence.py`
  - `calculate_metrics(...)` → `calc_metrics.py`
  - `generate_findings(...)` → `findings_engine.py`
  - `generate_report(...)` → `report_generator.py`

### Selection (single source of truth)
- `server/app/services/fact_selector.py`
  - Any “best metric” logic must live here.

### Report
- `server/app/services/report_generator.py`
  - Consumes canonical metrics + findings.

## Board-member mental model (how this maps to the product)

From the thread:

- A board member’s job is not “understand everything”; it’s:
  1) detect what changed,
  2) decide if it matters,
  3) challenge management with evidence.

Therefore the system should:
- lead with **exceptions** (top 2–3 issues)
- show calibration (inside/outside typical range)
- include evidence links (doc/page)
- detect restatements across packs

## Key improvements needed to hit the objective

### 1) Raise data quality before persistence (future)
Current issue: PDF extraction can create junk values that pass through.

Needed:
- A validation/scoring step before inserting into `financial_metrics`.
- Quarantine “bad” rows (still stored, but not used).

### 2) Make canonicalisation and scale detection robust
Big board-pack issue:
- values can be in £, £000, £m. If not normalised, comparisons are garbage.

Needed:
- Detect and store `scale` and normalise numeric values.
- Store currency consistently.

### 3) Move from hard-coded KPI logic → configurable KPI set
Right now we focus on Revenue first.

Needed:
- Extend to Gross Profit, EBITDA, Cash, Net Debt, Working Capital.
- Config-driven (YAML), not hard-coded.

### 4) Make findings the single source of prioritisation
The report should rely on findings for the “front page” priorities.

Needed:
- The report should show:
  - Top 3 findings
  - Top 10 questions
  - Evidence summaries
  - Data-quality warnings when insufficient reliable data exists

### 5) Restatement semantics (period closed / “should not move”)
Restatements should be more severe when:
- the period is “closed” (already in past quarter)
- repeated changes happen across multiple later packs

Needed:
- A “period closed” concept.
- Historical trail of values per doc with comparison logic.

### 6) Agent ergonomics
Needed:
- One-page “how to run” and “where to add a new finding”.
- Small fixtures for regression tests (1–2 PDFs / 1 CSV).

## Agent rules (to keep it simple)

- One pipeline only: extend `server/main.py` → `server/app/api/v1/endpoints/*` → `server/app/services/pipeline_processor.py`.
- One selector only: edit selection in `server/app/services/fact_selector.py`, import everywhere else.
- One prioritisation mechanism: prioritisation outputs only via `reconciliation_findings` (generated in `server/app/services/findings_engine.py`).
- One report generator: output only via `server/app/services/report_generator.py`.
- Prefer config over hardcode: thresholds and KPI lists live in `config/board_pack.yaml`.

## How to extend (agent playbook)

### Add a new KPI finding
1) Add config in `config/board_pack.yaml`.
2) Implement computation in `server/app/services/findings_engine.py`.
3) Store output as `reconciliation_findings` with `evidence`.
4) Ensure `report_generator.py` surfaces the finding + questions.

### Add a new reconciliation check
- Put it in `findings_engine.py` as deterministic logic.
- Keep evidence JSON “explainable” and linkable.

### Update selection logic
- Only edit selection in `server/app/services/fact_selector.py`.
- Do not re-implement selection in each consumer.

## Notes on current limitations

- PDF parsing remains the biggest quality risk.
- The v0.4 revenue narrative is “best-effort” and will be volatile until scale + period parsing are robust.
- If data is missing or filtered, the report should say so explicitly rather than printing nonsense.

## Known doc drift / cleanup candidates

- Older docs described a Node.js backend and a `server/scripts/` directory; the repo currently runs FastAPI via `server/main.py` and the pipeline code lives in `server/app/services/`.
- Consider either updating `CLAUDE.md` or deleting it to avoid sending agents down the wrong path.
- `server/main_old.py` appears unused by the canonical startup path; treat as legacy.
